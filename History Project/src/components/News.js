import React from 'react';
import './News.css'

const News = () => {
    return (
        <div className="container">
            {/* <h1 className="text-center" style={{paddingTop: "30%"}}>
                News
            </h1> */}
            <div class="site-wrap">
  <section data-scroll>
    <h1 data-splitting>Equity in the “Data Religion” Era</h1>
    
    <p>Oftentimes, we, the general public, tend to mistake sophistication with accuracy and repetition with truth. Unfortunately, this practice becomes a huge fallacy in the human’s modern imperative of uncovering the realities behind the systems we engage with on a daily basis. As Bill Foster, the leader of a webinar on Equitable Algorithms, points out: “AI can inherently be biased.” In fact, credit markets often reflect our nation’s history of discrimination. According to Melissa Koida, 20% of US adults lack a sufficient credit history to be scored and another 30% struggle to access affordable credit because their scores are non-prime. Additionally, nearly 30% of African-Americans and Hispanics cannot be scored under traditional means, compared to 16% of whites and Asians. Lisa Rice further scrutinizes the lending and housing systems in place in America by unveiling that 40% of black adults in Detroit, Michigan are credit invisible. All of these statistics prove that current methodologies in place within financial institutions are unequitable and further discriminatory practices. As Bill Foster states, “No one should be denied the opportunity to own a home, a pillar of the American dream, because of a non-human automated and awful unlawfully discriminatory decision.” However, making AI fair is much easier said than done. To truly initiate change in the procedures of these monetary establishments, Lisa Rice suggests “ Integrat[ing] review of racial and other forms of bias into every phase of the algorithm’s life cycle, including data selection, development, deployment, and monitoring” and ensuring “AI stakeholders, including regulators, scientists, engineers, and more [are] trained on fair housing and fair lending issues.” None of the panelists disagree with the notion that AI can greatly exceed our goals for equality, but all agree that achieving them will take a great level of cooperation between, our government, corporate enterprises, and the public. Stephen Hayes introduces the distinction between disparate treatment disparate impact, which are terms for the intentional and unintentional challenges caused for minorities due to unethical systems utilized by banking institutions at assessing creditworthiness and other metrics that are essential to living an enriching life. Hayes suggests that substituting “variables in the models with the goal of identifying variations of models that maintain performance but that have less disparate impact” is beneficial for companies and consumers. Additionally, he states that more holistic efforts, such as “fair lending training for modelers, ensuring teams have diverse backgrounds, and reviewing policies within which models operate” are also helpful courses of action. He believes that companies do not want to further discrimination, but finds it difficult to locate machine learning models that can detect accurately. Kareem Saleh offers further insight into the aforementioned practice, suggesting that although this method of “taking credit scores out of an algorithm, rerunning it, and evaluating the differences in outcomes for protected groups” may result in fairer outcomes, it is often less profitable for the company. These businesses have no guidance as to how they should handle the trade-off between profitability and equitability. Additionally, “lenders fear that the very act of trying to find a fairer better means of underwriting or pricing loans could be used against them as evidence they knew their algorithms were biased, to begin with.” Surprisingly, there are models that can disentangle a credit score’s predictive power from its disparity driving effects, which results in an increased approval rate for protected groups of about 10-30% without increasing risk for banks. He also mentions that policymakers can further assist by establishing goals or practices for balancing profitability with equitability. Overall, everybody agrees that AI models will have a large impact on the financial institutions within America, and everybody sees their extraordinary potential for good, but the challenge is ensuring that at every step of the process of advancing machines fair outcomes are prioritized.</p>
  <a href="https://www.youtube.com/watch?v=t7EmCHL5bHs">Video Conference</a>
  </section>
  <section data-scroll>
    <h1 data-splitting>Technology-Promoted Racism</h1>
    <p>Dr. Safiya Umoja Noble was surprised when Google first emerged and people began utilizing it as a trusted resource when she reckoned it was really just an advertising platform. When she searched “Black girls” on the website, Google returned pornography and hyper-sexualized content. Although Google began to suppress some of this content in 2012, Latina and Asian girls were still represented this way. In fact, a Markup study found that black girls, latina girls, and asian girls were profoundly linked with adult content while only “white girls” and “white boys” did not return pornographic keywords. A combination of hyperlinking, advertising and capital, and what people click on drives what we find on the web. Additionally, Google utilizes the data gathered from clicks on advertisements to repeatedly employ the same advertisements that garner the most attention. Consequently, many of the advertisements relate to pornographic material.
    One of the hardest stories for Dr. Safiya Umoja Noble to investigate was the Charleston church shooting. She learned that in trying to make sense of the trial of George Zimmerman, a neighborhood watchman in Florida who unjustifiably shot and killed 17-year-old Trayvon Martin, Dylann Roof stumbled across the Council of Conservative Citizens website, a deeply racist community. This website spreads disinformation, such as claiming that more Black people kill white people than white people do when, in reality, FBI data suggests 2,594 white people killed white people and 566 Black people killed white people. After traveling down a rabbit hole of white supremacy websites, Roof murders nine African-Americans and says he wants to start a race war.
Dr. Latanya Sweeney was the first African-American to get a PhD in Computer Science at MIT. During a meeting, she typed in her name to Google search to pull up some information about herself. Instead, she and the person she was meeting with were startled by an advertisement that appeared which suggested she had a criminal record. Upon clicking on the advertisement, nobody with her name had any arrest records on the website. Pursuing this discovery further, Sweeney found that white-associated names most often resulted in neutral ad, while Black-associated names resulted in ads indicating an arrest record more than 80% of the time. She remarks that we do not have much policy over these systems, yet they dictate how we live.
</p>
<a href="https://www.youtube.com/watch?v=9K9ZR_lGRpY">Documentary</a>
      </section>

      <section data-scroll>
    <h1 data-splitting>Identifying Unethical Uses of Tech</h1>
    <p>Worries about robots replacing humans in the workforce have been circulating for centuries. So far, data has shown that increases in automation result in more jobs. Projections from the WEF reiterate this data, suggesting that, although machines might eliminate 85 million occupations by 2025, 97 million jobs are expected to be created in that time period. While the declining rate of jobs may become much more significant in the future as the efficiency of Artificial Intelligence grows at an exponential rate, for now, there are more pressing ethical concerns around technological growth than the workplace. Not only are there the previous articles I have written that cover the systemic racism inherent in algorithms, but there are also newfound technologies that post just as significant ethical dilemmas. For example, CRISPR may allow people to not only cure mental and physical illnesses but give themselves preferable characteristics. According to UCSF, this future might be just 30 years away. Brain-machine interfaces and other implantable and external biotechnology also must be explored safely. Governments have been known to test futuristic technologies without much caution or care for human life, and a mistake in this new era of advancement could truly be catastrophic to all of humanity.
</p>
<a href="https://magazine.ucsf.edu/technology-will-soon-give-us-precise-control-over-our-brains-and-genes">UCSF Statistics</a>
<a className='a10' href="https://www.cnbc.com/2020/10/20/wef-says-machines-will-create-jobs-but-warns-of-pandemic-disruption.html">WEF Job Data</a>
  
      </section>

</div>
        </div>
    )
}
export default News;